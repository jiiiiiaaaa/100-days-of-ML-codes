{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Day 1](https://github.com/MachineLearning100/100-Days-Of-ML-Code/raw/master/Info-graphs/Day%201.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 导入数据集\n",
    "pd.iloc 提取指定的行和列  \n",
    "· 利用iloc提取所有数据  \n",
    "data.iloc[:,:] #取第所有列的所有行  \n",
    "\n",
    "· 利用iloc提取所选列数据  \n",
    "data.iloc[:,[0]] #取第0列所有行，多取几列格式为 data.iloc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:,:-1].values # 除了最后一列的所有数据\n",
    "Y = dataset.iloc[:,3].values # 最后一列（第4列）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 处理丢失数据\n",
    "可以用整列的平均值或中间值替换丢失的数据。  \n",
    "用sklearn.preprocessing库中的Imputer类完成这项任务。  \n",
    "\n",
    "`sklearn.preprocessing.Imputer(missing_values=’NaN’, strategy=’mean’, axis=0, verbose=0, copy=True)`\n",
    "\n",
    "主要参数说明：\n",
    "1. missing_values：缺失值，可以为整数或NaN(缺失值numpy.nan用字符串‘NaN’表示)，默认为NaN\n",
    "2. strategy：替换策略，字符串，默认用均值‘mean’替换\n",
    "    ① 若为mean时，用特征列的均值替换\n",
    "    ② 若为median时，用特征列的中位数替换\n",
    "    ③ 若为most_frequent时，用特征列的众数替换\n",
    "3. axis：指定轴数，默认axis=0代表列，axis=1代表行\n",
    "4. copy：设置为True代表不在原数据集上修改，设置为False时，就地修改，存在如下情况时，即使设置为False时，也不会就地修改\n",
    "    ① X不是浮点值数组\n",
    "    ② X是稀疏且missing_values=0\n",
    "    ③ axis=0且X为CRS矩阵\n",
    "    ④ axis=1且X为CSC矩阵\n",
    "5. statistics_属性：axis设置为0时，每个特征的填充值数组，axis=1时，报没有该属性错误\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:,1:3]) # 用数据拟合X的第二列和第三列\n",
    "X[:,1:3] = imputer.transform(X[:,1:3]) # 补充缺失数据\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 解析分类数据\n",
    "将标签值（非数字）解析为数字。  \n",
    "用sklearn.preprocessing库中的LabelEncoder, OneHotEncoder类。  \n",
    "* LabelEncoder 可以将标签分配一个0 — n_classes-1之间的编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 44.0 72000.0]\n",
      " [2 27.0 48000.0]\n",
      " [1 30.0 54000.0]\n",
      " [2 38.0 61000.0]\n",
      " [1 40.0 63777.77777777778]\n",
      " [0 35.0 58000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [1 50.0 83000.0]\n",
      " [0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LabelEncoder_X = LabelEncoder()\n",
    "X[:,0] = LabelEncoder_X.fit_transform(X[:,0]) # 给第一列分类编码\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建虚拟变量\n",
    "* OneHotEncoder 独热编码，采用位状态寄存器来对个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.40000000e+01 7.20000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 3.00000000e+01 5.40000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.50000000e+01 5.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.87777778e+01 5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e+01 8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.70000000e+01 6.70000000e+04]] \n",
      " [0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "LabelEncoder_Y = LabelEncoder()\n",
    "Y = LabelEncoder_Y.fit_transform(Y)\n",
    "\n",
    "print(X,'\\n',Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 将数据集拆分为训练集和测试集\n",
    "两者一般的比例为80:20。  \n",
    "用sklearn.crossvalidation库中的train_test_split。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.70000000e+01 6.70000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.87777778e+01 5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.40000000e+01 7.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.50000000e+01 5.80000000e+04]] \n",
      " [[0.0e+00 1.0e+00 0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04]\n",
      " [0.0e+00 1.0e+00 0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]] \n",
      " [1 1 1 0 1 0 0 1] \n",
      " [0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2, random_state = 0)\n",
    "print(X_train,'\\n',X_test,'\\n',Y_train,'\\n',Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 特征量化\n",
    "用特征标准化或Z值归一化解决特征缩放的问题。  \n",
    "使用sklearn.preprocessing库中的StandardScaler类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          1.         -1.          2.64575131 -0.77459667  0.26306757\n",
      "   0.12381479]\n",
      " [ 1.         -1.          1.         -0.37796447 -0.77459667 -0.25350148\n",
      "   0.46175632]\n",
      " [-1.          1.         -1.         -0.37796447  1.29099445 -1.97539832\n",
      "  -1.53093341]\n",
      " [-1.          1.         -1.         -0.37796447  1.29099445  0.05261351\n",
      "  -1.11141978]\n",
      " [ 1.         -1.          1.         -0.37796447 -0.77459667  1.64058505\n",
      "   1.7202972 ]\n",
      " [-1.          1.         -1.         -0.37796447  1.29099445 -0.0813118\n",
      "  -0.16751412]\n",
      " [ 1.         -1.          1.         -0.37796447 -0.77459667  0.95182631\n",
      "   0.98614835]\n",
      " [ 1.         -1.          1.         -0.37796447 -0.77459667 -0.59788085\n",
      "  -0.48214934]] \n",
      " [[-1.          1.         -1.          2.64575131 -0.77459667 -1.45882927\n",
      "  -0.90166297]\n",
      " [-1.          1.         -1.          2.64575131 -0.77459667  1.98496442\n",
      "   2.13981082]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "print(X_train,'\\n',X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
